
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Welcome to Rateme’s Documentation &#8212; Rateme  documentation</title>
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
  </head>
  <body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="#">Rateme  documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="toctree-wrapper compound">
</div>
<div class="section" id="welcome-to-rateme-s-documentation">
<h1>Welcome to Rateme’s Documentation<a class="headerlink" href="#welcome-to-rateme-s-documentation" title="Permalink to this headline">¶</a></h1>
</div>
<div class="section" id="source-code-documentation">
<h1>Source code documentation<a class="headerlink" href="#source-code-documentation" title="Permalink to this headline">¶</a></h1>
<p>Rateme’s API can be found at:</p>
<ul class="simple">
<li><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></li>
<li><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></li>
</ul>
</div>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<p><strong>Goal</strong></p>
<p>RateMe is a trial project developed for evaluating the image attractiveness. Using this service, people could upload their images and get a private objective score. In that way, users could obtain the most likely rating before post their photos on social media.</p>
<p><strong>Methods we used</strong></p>
<p>RateMe’ design allows to perform a scientific look evaluation. The score is calculated based on more than 7500 images from scraped from reddit. We used tpot and tensor flow to implement machine learning algorithms and analise the relation between image’ features and score obtained. Then, with this information we predict the score for new inputs.</p>
<p><strong>Analysis and results</strong></p>
<p>First results reveal the complexity of performing a good evaluation, given the highly different kind of images uploaded by the users. The accuracy of the results was enhanced when we focused just on user’s face and applying gray-scale filter. The analysis also exposed the relation between photo’s comments and score given the gender.</p>
<p><strong>Future work</strong></p>
<p>RateMe could be used to predict image score, but also to find insights about social patterns related with the gender and age.  Future work could include also extend the application to suggest users how to improve their photos to have higher ratings or help users to choose best image for CV or profile picture.</p>
</div>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<p>Rateme can be installed from scratch using the following commands:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">rateme</span><span class="o">-</span><span class="n">hyids17</span><span class="o">/</span><span class="n">Rateme</span><span class="o">.</span><span class="n">git</span>
<span class="n">cd</span> <span class="n">Rateme</span>
<span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">r</span> <span class="n">requirements</span><span class="o">.</span><span class="n">txt</span>
</pre></div>
</div>
<p><strong>We have tested our program in:</strong></p>
<ul class="simple">
<li>Linux Ubuntu 16.x, 17.x, MacOS Sierra</li>
<li>Python 3.5.x 64 bits (tensorflow requires 64bits)</li>
</ul>
<p>We anticipate that the program also works in other OS(s), but there might be some problems due to 3rd party python package installations. For example, in Windows some of the modules require installation by wheel (pip fails).</p>
<p><strong>Reddit API</strong></p>
<p>In order to scrap data from reddit, you must have an access to Reddit API. Once you have it, you have to fill the required fields in <code class="docutils literal"><span class="pre">reddit_api.cfg</span></code> inside the Rateme folder.</p>
<p>This tutorial presents the procedure to get the Reddit API access <a class="reference external" href="http://pythonforengineers.com/build-a-reddit-bot-part-1/">Reddit API</a>.</p>
</div>
<div class="section" id="running-options">
<h1>Running options<a class="headerlink" href="#running-options" title="Permalink to this headline">¶</a></h1>
<p>User can check all the available options using:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">rateme</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">h</span>
</pre></div>
</div>
<p>This will show all the available arguments and values for usage:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">usage</span><span class="p">:</span> <span class="n">rateme</span><span class="o">.</span><span class="n">py</span> <span class="p">[</span><span class="o">-</span><span class="n">h</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">q</span> <span class="n">QUERY_LEVEL</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">a</span> <span class="n">APPLICATION_MODE</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">i</span> <span class="n">IMAGE</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">t</span><span class="p">]</span>

<span class="n">optional</span> <span class="n">arguments</span><span class="p">:</span>
 <span class="o">-</span><span class="n">h</span><span class="p">,</span> <span class="o">--</span><span class="n">help</span>
           <span class="n">show</span> <span class="n">this</span> <span class="n">help</span> <span class="n">message</span> <span class="ow">and</span> <span class="n">exit</span>

 <span class="o">-</span><span class="n">q</span> <span class="n">QUERY_LEVEL</span><span class="p">,</span> <span class="o">--</span><span class="n">query_level</span> <span class="n">QUERY_LEVEL</span>
           <span class="n">The</span> <span class="n">query</span> <span class="n">level</span> <span class="k">for</span> <span class="n">scraping</span> <span class="n">submissions</span> <span class="kn">from</span> <span class="nn">reddit</span><span class="o">/</span><span class="n">r</span><span class="o">/</span><span class="n">Rateme</span><span class="o">.</span> <span class="p">(</span><span class="n">DEFAULT</span><span class="p">:</span> <span class="o">-</span><span class="n">q</span> <span class="mi">1</span><span class="n">year</span><span class="p">)</span>
           <span class="n">Available</span> <span class="n">values</span><span class="p">:</span> <span class="mi">1</span><span class="n">day</span><span class="p">,</span> <span class="mi">1</span><span class="n">week</span><span class="p">,</span> <span class="mi">1</span><span class="n">month</span><span class="p">,</span> <span class="mi">3</span><span class="n">months</span><span class="p">,</span> <span class="mi">6</span><span class="n">months</span><span class="p">,</span> <span class="mi">1</span><span class="n">year</span><span class="p">,</span> <span class="mi">3</span><span class="n">years</span><span class="o">.</span>

 <span class="o">-</span><span class="n">a</span> <span class="n">APPLICATION_MODE</span><span class="p">,</span> <span class="o">--</span><span class="n">application_mode</span> <span class="n">APPLICATION_MODE</span>
           <span class="n">Choose</span> <span class="n">application</span> <span class="n">mode</span> <span class="n">to</span> <span class="n">perform</span><span class="o">.</span> <span class="p">(</span><span class="n">DEFAULT</span><span class="p">:</span> <span class="o">-</span><span class="n">a</span> <span class="n">scrap</span><span class="p">)</span>
           <span class="n">Available</span> <span class="n">values</span><span class="p">:</span> <span class="n">scrap</span><span class="p">,</span> <span class="n">tpot</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span>

 <span class="o">-</span><span class="n">i</span> <span class="n">IMAGE</span><span class="p">,</span> <span class="o">--</span><span class="n">image</span> <span class="n">IMAGE</span>
           <span class="n">Image</span> <span class="n">path</span> <span class="n">to</span> <span class="n">be</span> <span class="n">predicted</span><span class="o">.</span>

 <span class="o">-</span><span class="n">t</span><span class="p">,</span> <span class="o">--</span><span class="n">train_scratch</span>
           <span class="n">Train</span> <span class="n">tpot</span> <span class="kn">from</span> <span class="nn">scratch.</span>
</pre></div>
</div>
<p><strong>Examples:</strong></p>
<p>The following will scrap 3 years of data from reddit.com/r/Rateme subreddit:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">rateme</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">a</span> <span class="n">scrap</span> <span class="o">-</span><span class="n">q</span> <span class="mi">3</span><span class="n">years</span>
</pre></div>
</div>
<p>Second example will train tpot pipeline from scratch and it will predict on given image:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">rateme</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">a</span> <span class="n">tpot</span> <span class="o">-</span><span class="n">t</span> <span class="o">-</span><span class="n">i</span> <span class="n">image</span><span class="o">/</span><span class="n">test</span><span class="o">.</span><span class="n">jpg</span>
</pre></div>
</div>
<p>Third example will predict the given image using already fitted pipeline in tpot:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">rateme</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">a</span> <span class="n">tpot</span> <span class="o">-</span><span class="n">i</span> <span class="n">image</span><span class="o">/</span><span class="n">test</span><span class="o">.</span><span class="n">jpg</span>
</pre></div>
</div>
<p>Last example will predict the given image using Neural Network:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">rateme</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">a</span> <span class="n">nn</span> <span class="o">-</span><span class="n">i</span> <span class="n">image</span><span class="o">/</span><span class="n">test</span><span class="o">.</span><span class="n">jpg</span>
</pre></div>
</div>
</div>
<div class="section" id="results">
<h1>Results<a class="headerlink" href="#results" title="Permalink to this headline">¶</a></h1>
<p>Our goal was to fit a machine learning model to a data set of pictures with ratings as labels, in order to predict the attractivness of new pictures. Only male images were used in the training, because attractivness criteria might differ between the sexes and almost all images were male.</p>
<p>First we tried to retrain the last layer of a neural network called Inception-v3 (<a class="reference external" href="https://www.tensorflow.org/tutorials/image_recognition">https://www.tensorflow.org/tutorials/image_recognition</a>), that is trained to recognize a 1000 different object classes in images. We used a retrainer provided by TensorFlow for the task (<a class="reference external" href="https://www.tensorflow.org/tutorials/image_retraining">https://www.tensorflow.org/tutorials/image_retraining</a>). The images were divided into classes from 3 to 9 based on the rounded rating. Classes 1, 2 and 10 were omitted due to lack of samples. The resulting neural network got a 20% test accuracy, which wasn’t great, but still better than a completely random guess of 14%.</p>
<p>We also tried if tpot could find a good regressor for the task. For this we extracted the faces from the images using a Haar Cascades (<a class="reference external" href="https://docs.opencv.org/master/d7/d8b/tutorial_py_face_detection.html">https://docs.opencv.org/master/d7/d8b/tutorial_py_face_detection.html</a>) and transformed the faces into 64x64 grayscale images. For this data tpot achieved average distance from the true score of 1.31 in the test set. We also used the rounded prediction and compared it to the rounded true label to get a similar accuracy measure to the neural network, reaching 27%, which is way better than the network’s 20%. This might be due to overfitting though, because most of the images were concentrated in just a couple of classes (6, 7 and 8). The tpot’s chosen model was RidgeCV.</p>
<p>In addition we experimented with dimensionality reduction on the data before learning with tpot, because a 64x64 grayscale image has 4096 features, and all of the are probably not that important. The reduction methods used were PCA (with 50, 1000 and 2048 components) and linear discriminant analysis, but both produced worse results than the raw data with all 4096 features.</p>
<p>Lastly we tried applying Gabor filters on the images. Gabor filters have been used in texture analysis, so we thought they might help in extracting useful features. This didn’t improve results.</p>
<p>Our next idea was to extract features, such as does the image have a smile, using Haar Cascades. Then we could do analysis of what kind of features attractive images tend to have. This failed however, because the Haar Cascades did a horrible job. Only the face detection really works and even then you have to select the largest face found, because the classifier finds faces in all kinds of weird places.</p>
</div>
<div class="section" id="analysis">
<h1>Analysis<a class="headerlink" href="#analysis" title="Permalink to this headline">¶</a></h1>
<dl class="docutils">
<dt>We have collected information from users for different periods of time:</dt>
<dd><ul class="first last simple">
<li>1 day</li>
<li>1 week</li>
<li>1 month</li>
<li>3 months</li>
<li>6 months</li>
<li>1 year</li>
<li>3 years</li>
</ul>
</dd>
</dl>
<p>We started analysing the original data distributions to identify common patterns, outliers and the minimum number of samples necessary to perform the prediction.</p>
<div class="figure align-center" id="id1">
<a class="reference internal image-reference" href="images/1.png"><img alt="map to buried treasure" src="images/1.png" style="width: 500px; height: 400px;" /></a>
<p class="caption"><span class="caption-text"><em>Figure 1. Gender histogram.</em></span></p>
</div>
<p>Figure 1 shows the gender histogram, it revels the difference in female and male samples. The number of samples is similar for low periods (1 day, 1 week), then it starts raising for male samples. From 1 year samples, the difference in frequency is stable.</p>
<div class="figure align-center" id="id2">
<a class="reference internal image-reference" href="images/2.png"><img alt="map to buried treasure" src="images/2.png" style="width: 500px; height: 400px;" /></a>
<p class="caption"><span class="caption-text"><em>Figure 2. Age histogram.</em></span></p>
</div>
<p>In terms of age, samples are mostly distributed between 19 and 28 years old. The second interest group is the one for people under 19 years old. On the other hand, people over 28 years old represents less than the 50% of the second interest group. We also see the same behavior as in Gender histogram regarding sampling period.</p>
<div class="figure align-center" id="id3">
<a class="reference internal image-reference" href="images/3a.png"><img alt="map to buried treasure" src="images/3a.png" style="width: 500px; height: 400px;" /></a>
<p class="caption"><span class="caption-text"><em>Figure 3a. Box-plot, score distributions by period of time</em></span></p>
</div>
<div class="figure align-center" id="id4">
<a class="reference internal image-reference" href="images/3b.png"><img alt="map to buried treasure" src="images/3b.png" style="width: 500px; height: 200px;" /></a>
<p class="caption"><span class="caption-text"><em>Figure 3b. Box-plot, score distributions by gender:</em></span></p>
</div>
<p>Figures 3a and 3b show the distribution of the score grouped by periods of time and gender. In general, the score is distributed between 5.5 and 8 points.  Means and medians are similar for samples greater than 3 months, below this number data is sparse and misclassification could be more possible. On the other hand, male scores tend to be more diverse than female ones, which would make difficult for prediction tasks, given that differences between pictures could be tiny.</p>
<div class="figure align-center" id="id5">
<a class="reference internal image-reference" href="images/4a.png"><img alt="map to buried treasure" src="images/4a.png" style="width: 500px; height: 400px;" /></a>
<p class="caption"><span class="caption-text"><em>Figure 4a. Comments distribution:</em></span></p>
</div>
<div class="figure align-center" id="id6">
<a class="reference internal image-reference" href="images/4b.png"><img alt="map to buried treasure" src="images/4b.png" style="width: 500px; height: 400px;" /></a>
<p class="caption"><span class="caption-text"><em>Figure 4b. Comments distribution.</em></span></p>
</div>
<p>Figure 4 shows the patterns found concerning with comments. The number of comments does not seem to be affected by period of time, which is logic given that it should depends on factors closer to picture composition. It is outstanding the relation between comments-gender compared with score distributions due to score for males is more spread, however comments are highly clustered in less than 10 comments, while female picture comments are very diverse and get the highest numbers. This statement is clearer in Figure 4b, where we also confirm the relation comments-score (high score pictures tends to have more comments, and this is stronger for female pictures.)</p>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="#">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Welcome to Rateme’s Documentation</a></li>
<li><a class="reference internal" href="#source-code-documentation">Source code documentation</a></li>
<li><a class="reference internal" href="#summary">Summary</a></li>
<li><a class="reference internal" href="#setup">Setup</a></li>
<li><a class="reference internal" href="#running-options">Running options</a></li>
<li><a class="reference internal" href="#results">Results</a></li>
<li><a class="reference internal" href="#analysis">Analysis</a></li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="#">Rateme  documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2017, Ege Can Ozer, Otto Hantula, Agustin Zuniga.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.5.
    </div>
  </body>
</html>